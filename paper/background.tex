\section{Related Work}

\section{Background}

\subsection{Bisimulation Relations}

\subsection{Modules and $\Z{n}$}

On processors, arithmetic does not happen over $\mathbb{Z}$, but
rather over a space of bitvectors. Mathematically, we can model
an $n$-bit bitvector as an element of $\Z{n}$, that is integers
modulo $2^n$. In the course of our work, we deal with vectors and
matrices over $\Z{n}$ and compute solutions to linear equations over
matrices. However, because the space $\Z{n}$ is not a field, but
rather only a commutative ring, the traditional treatment of linear
algebra does not fully apply. Instead of \emph{vector spaces} we
have \emph{$\Z{n}$-modules}. There are many parallels between vector
spaces and modules, and we need not dwell on them at length. In both
settings, we have the concept of a \emph{basis} or \emph{generating
set} where linear combinations of a set of vectors generate an
entire space. However, a key difference is that in modules we do
not have the concept of linear independence. Rather, there is no
well-defined notion of dimension for a module. As a result, when
reading about modules, some of the traditional concepts from linear
algebra over fields apply, but not all do. Note that linear algebra
over $\mathbb{Z}$ is easier than linear algebra over $\Z{64}$ because
the integers form a \emph{principal integral domain} (PID), allowing
the construction of the field of fractions $\mathbb{Q}$; however,
$\Z{n}$ is not a PID and thus no field of fractions exists. For a
systematic treatment of modules, please see \todo{citation needed}.


