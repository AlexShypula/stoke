\section{Related Work}\label{sec:related}

The most similar work to ours is that of~\cite{Dahiya17ASPLAS}. The
authors perform black-box equivalence checking across a variety of
compiler optimizations. Their technique rests on the assumption that
given a branch in the rewrite program that executes on condition $C$,
there exists a corresponding branch in the target program that executes
with the same condition. This assumption holds for a variety of
compiler optimizations, but it doesn't hold for many vectorization
examples (such as that presented in Section~\ref{sec:example}). Also,
it is asymmetric: with this technique, sometimes one can prove that a
target is equivalent to a rewrite, but not the other way around.

Translation validation seeks to verify\todo{cite cite cite}
the correctness of compiler optimizations. Typically, this
depends on instrumenting the compiler to help generate
the bisimulation relation for each compilation. However,
maintaining this instrumentation and the corresponding
validation tool along with the compiler is prohibitively time
intensive, and this approach does not apply to domains such as
superoptimization~\cite{Massalin1987,Schkufza2013,Churchill2017} or in
verifying optimizations performed manually (as in our case study of
\libc{} strlen) where there is no compiler to instrument.

In the literature of translation validation, equivalence checking,
and relational verification, many works assume that loop executions
of the target are in one-to-one correspondence with loop executions
of the rewrite, meaning that both programs execute each loop the same
number of times. This assumption does not allow the verification of
loop unpeeling, loop unrolling, nor vectorization optimizations.
The assumption helps validate new verification techniques,
especially when dealing with loops generally is an intractable
problem, but is inapplicable in most real-world optimization
settings. Some examples include past work on data-driven equivalence
checking~\cite{Sharma2013}, Necula's well-known translation validation
work~\cite{Necula2000}, and others~\cite{Fedykovich2015}. \todo{cite
more}

Some works instead use manually-provided inputs to generate the
control flow correspondence. For example, in~\cite{Kundu2009}
the authors prove the correctness of some difficult compiler
optimizations, such as loop interchange, by using programmer-supplied
templates which imply a correspondence. Other works allow users to
specify ``control flow synchronization points" to be placed manually
by the user~\cite{Kiefer2016}.

An alternative approach is to use powerful solvers, such as those for
constrained Horn clauses, to fully reason about a pair of programs in
question and to prove equivalence. This achieves equivalence checking,
but does not explicitly construct a control flow correspondence
between two programs. It is, however, limited by the ability of the
solver to reason about possibly undecidable problems.\todo{learn more
about this and cite}

There are several other approaches that avoid creating an explicit
control flow correspondence. One approach involves described
in~\cite{Tristan2011} involves building value-graphs for a target and
rewrite program, normalizing the graphs via a series of rewrite rules,
and checking for equality. The effectiveness of this approach is
limited by the ability to reason about a fixpoint operator that models
loops; however, the authors haven't explained what loop optimizations
it can and cannot handle\todo{re-read the paper and make very sure
this is true}. In general, without a control flow correspondence, a
number of properties relating two programs are obscured.

There is still a fruitful line of research in verifying the
correctness of peephole optimizations without loops~\cite{Lopes2015},
where authors make progress on problems such as modeling undefined
behavior.

Our key contribution, therefore, is the construction of a control-flow
correspondence without manual input from the user, instrumentation
of the compiler, or assumptions that the branch conditions of the
target and rewrite programs match. Instead, we use test cases either
provided by the user or generated by an SMT solver to learn and prove
the correspondence.

